{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import bs4 as bs\n",
    "import urllib.request\n",
    "import re\n",
    "\n",
    "q1 = \"Mustafa_Kemal_Atatürk\"\n",
    "q2 = \"Donald_Trump\"\n",
    "\n",
    "# Gettings the data source\n",
    "from urllib.parse import quote  \n",
    "source = urllib.request.urlopen('https://en.wikipedia.org/wiki/'+ quote(q1)).read()\n",
    "\n",
    "# Parsing the data/ creating BeautifulSoup object\n",
    "soup = bs.BeautifulSoup(source,'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching the data\n",
    "text = \"\"\n",
    "for paragraph in soup.find_all('p'):\n",
    "    text += paragraph.text\n",
    "\n",
    "# Preprocessing the data\n",
    "text = re.sub(r'\\[[0-9]*\\]',' ',text)\n",
    "text = re.sub(r'\\s+',' ',text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/uzaycetin/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "import heapq\n",
    "\n",
    "#Preprocessing the data\n",
    "text = re.sub(r'\\[[0-9]*\\]',' ',text)\n",
    "text = re.sub(r'\\s+',' ',text)\n",
    "clean_text = text.lower()\n",
    "clean_text = re.sub(r'\\W',' ',clean_text)\n",
    "clean_text = re.sub(r'\\d',' ',clean_text)\n",
    "clean_text = re.sub(r'\\s+',' ',clean_text)\n",
    "\n",
    "# Tokenize sentences\n",
    "sentences = nltk.sent_tokenize(text)\n",
    "\n",
    "# Stopword list\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word counts \n",
    "word2count = {}\n",
    "for word in nltk.word_tokenize(clean_text):\n",
    "    if word not in stop_words:\n",
    "        if word not in word2count.keys():\n",
    "            word2count[word] = 1\n",
    "        else:\n",
    "            word2count[word] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting counts to weights\n",
    "maxi = max(word2count.values())\n",
    "for key in word2count.keys():\n",
    "    word2count[key] = word2count[key]/maxi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Product sentence scores    \n",
    "sent2score = {}\n",
    "for sentence in sentences:\n",
    "    for word in nltk.word_tokenize(sentence.lower()):\n",
    "        if word in word2count.keys():\n",
    "            if len(sentence.split(' ')) < 15:\n",
    "                if sentence not in sent2score.keys():\n",
    "                    sent2score[sentence] = word2count[word]\n",
    "                else:\n",
    "                    sent2score[sentence] += word2count[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------\n",
      "In 1934, Mustafa Kemal commissioned the first Turkish operatic work, Özsoy.\n",
      "Mustafa Kemal dealt with the translation of scientific terminology into Turkish.\n",
      "He also introduced the Latin-based Turkish alphabet, replacing the old Ottoman Turkish alphabet.\n",
      "Mustafa Kemal himself travelled the countryside in order to teach citizens the new alphabet.\n",
      "Mustafa Kemal said: There is no logical explanation for the political disenfranchisement of women.\n",
      "Afghan Foreign Minister Mahmud Tarzi was a follower of Mustafa Kemal's domestic policy.\n",
      "Mustafa Kemal generated media attention to propagate modern education during this period.\n",
      "Mustafa Kemal, then the President, occupied a powerful position in this political system.\n",
      "Mustafa Kemal first made the hat compulsory for civil servants.\n",
      "The initial choices of Mustafa Kemal's economic policies reflected the realities of his period.\n"
     ]
    }
   ],
   "source": [
    "#Gettings best 10 lines             \n",
    "best_sentences = heapq.nlargest(10, sent2score, key=sent2score.get)\n",
    "\n",
    "print('---------------------------------------------------------')\n",
    "for sentence in best_sentences:\n",
    "    print(sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------\n",
      "Trump has repeatedly denied any collusion between the Trump campaign and the Russian government.\n",
      "In 2001, Trump completed Trump World Tower.\n",
      "Mueller can subpoena Trump to testify if Trump refuses.\n",
      "Melania became First Lady when Trump became president in January 2017.\n",
      "Trump said his wealth would make him immune to pressure from campaign donors.\n",
      "Trump was born and raised in the New York City borough of Queens.\n",
      "NPR said that Trump's campaign statements were often opaque or suggestive.\n",
      "During his presidential campaign, Trump was accused of pandering to white supremacists.\n",
      "As president, Trump has frequently made false statements in public speeches and remarks.\n",
      "On May 18, 2018, Trump announced the United States' unilateral departure from the JCPOA.\n"
     ]
    }
   ],
   "source": [
    "#Gettings best 10 lines             \n",
    "best_sentences = heapq.nlargest(10, sent2score, key=sent2score.get)\n",
    "\n",
    "print('---------------------------------------------------------')\n",
    "for sentence in best_sentences:\n",
    "    print(sentence)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
