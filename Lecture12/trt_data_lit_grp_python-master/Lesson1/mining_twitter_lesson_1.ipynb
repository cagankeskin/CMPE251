{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "@Creator: Cindy Zhong\n",
    "@Date: December 05, 2016\n",
    "@Name: mining_twitter_lesson_1.py\n",
    "\"\"\"\n",
    "from __future__ import division\n",
    "from twython import Twython, TwythonError\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "twitter_creds_df = pd.read_csv(\"twitter_creds.csv\")\n",
    "\n",
    "APP_KEY = twitter_creds_df.ix[0,0]\n",
    "APP_SECRET = twitter_creds_df.ix[1,0]\n",
    "OAUTH_TOKEN = twitter_creds_df.ix[2,0]\n",
    "OAUTH_TOKEN_SECRET = twitter_creds_df.ix[3,0]\n",
    "\n",
    "twitter = Twython(APP_KEY, APP_SECRET,OAUTH_TOKEN, OAUTH_TOKEN_SECRET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Understanding the Twitter API - What Does the Response Look Like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's look at the results twitter returns when we send a request through the API\n",
    "user_timeline = twitter.get_user_timeline(screen_name=\"realDonaldTrump\",count=1)\n",
    "\n",
    "# Walk through the result returned\n",
    "# example:\n",
    "print user_timeline[0]['text']\n",
    "print user_timeline[0]['user']['followers_count']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting Timeline for a particular user, over coming the rate limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's fetch all of Trump and Hilary's tweets\n",
    "api = twitter # Twitter authentication\n",
    "searchQuerys = ['realDonaldTrump','HillaryClinton']\n",
    "#create a dataframe to store the tweets\n",
    "tweet_fields = ['handle','tweet_body','tweet_created_at','likes','retweet','hashtags','user_mentions','place']\n",
    "tweet_df = pd.DataFrame(data=np.zeros((0,len(tweet_fields))), columns=tweet_fields)\n",
    "\n",
    "for searchQuery in searchQuerys:\n",
    "    maxTweets = 400 #Maximum number of tweets to download per user\n",
    "    max_id = -1L  #If results only below a specific ID are, set max_id to that ID\n",
    "    sinceId = None #no lower limit, go as far back as API allows\n",
    "    tweetCount = 0\n",
    "    tweetsPerQry = 200 #Number of tweets to grab per query, maximum is 100\n",
    "    print(\"Downloading max {0} tweets for handle {1}\".format(maxTweets,searchQuery))\n",
    "    while tweetCount < maxTweets:\n",
    "        try:\n",
    "            if (max_id <= 0):\n",
    "                if (not sinceId):\n",
    "                    new_tweets = api.get_user_timeline(screen_name=searchQuery, count=tweetsPerQry)\n",
    "                else:\n",
    "                    new_tweets = api.get_user_timeline(screen_name=searchQuery, count=tweetsPerQry,\n",
    "                                            since_id=sinceId)\n",
    "            else:\n",
    "                if (not sinceId):\n",
    "                    new_tweets = api.get_user_timeline(screen_name=searchQuery, count=tweetsPerQry,\n",
    "                                            max_id=str(max_id - 1))\n",
    "                else:\n",
    "                    new_tweets = api.get_user_timeline(screen_name=searchQuery, count=tweetsPerQry,\n",
    "                                            max_id=str(max_id - 1),\n",
    "                                            since_id=sinceId)\n",
    "            if not new_tweets:\n",
    "                print(\"No more tweets found\")\n",
    "                break\n",
    "            \n",
    "            for tweet in new_tweets:\n",
    "                #insert key information about tweets into our tweet_df\n",
    "                handle = searchQuery\n",
    "                tweet_body = tweet['text'].encode('utf-8')\n",
    "                tweet_created_at = datetime.strptime(tweet['created_at'],'%a %b %d %H:%M:%S +0000 %Y')\n",
    "                likes = tweet['favorited']\n",
    "                retweet = tweet['retweet_count']\n",
    "                hashtags = [h['text'] for h in tweet['entities']['hashtags']]\n",
    "                user_mentions = [user['name'] for user in tweet['entities']['user_mentions']]\n",
    "                if tweet['place'] != None:\n",
    "                    left_pt = tweet['place']['bounding_box']['coordinates'][0][0]\n",
    "                    right_pt = tweet['place']['bounding_box']['coordinates'][0][2]\n",
    "                    long_pt = (left_pt[0] + right_pt[0])/2\n",
    "                    lat_pt = (left_pt[1] + right_pt[1])/2\n",
    "                    place = (long_pt, lat_pt)\n",
    "                else:\n",
    "                    place = None\n",
    "                #append to our dataframe\n",
    "                tweet_ap = pd.DataFrame([[handle,tweet_body,tweet_created_at,likes,retweet,hashtags,user_mentions,place]],columns=tweet_fields)\n",
    "                tweet_df = tweet_df.append(tweet_ap, ignore_index = True)\n",
    "                \n",
    "            tweetCount += len(new_tweets)\n",
    "            \n",
    "            print(\"Downloaded {0} tweets\".format(tweetCount))\n",
    "                           \n",
    "            max_id = new_tweets[-1]['id']\n",
    "        \n",
    "        except TwythonError as e:\n",
    "            # Just exit if any error\n",
    "            print(\"some error : \" + str(e))\n",
    "            break\n",
    "        print (\"Downloaded {0} tweets, for handle {1}\".format(tweetCount,searchQuery))\n",
    "        #Take a break\n",
    "#        time.sleep(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some Exploratory Analytics on the Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now let's do some exploratory analytics with the tweets!\n",
    "from collections import Counter\n",
    "from bokeh.charts import Bar, output_file, show\n",
    "from bokeh.charts.attributes import cat\n",
    "from bokeh.layouts import row\n",
    "\n",
    "# A look at Hilary's Most used hashtags\n",
    "hilary_all_hashtags = [hashtag for t in tweet_df[tweet_df.handle != 'realDonaldTrump']['hashtags'] for hashtag in t]\n",
    "hilary_most_common_hashtags = Counter(hilary_all_hashtags).most_common(15)\n",
    "# A look at Trump's\n",
    "trump_all_hashtags = [hashtag for t in tweet_df[tweet_df.handle == 'realDonaldTrump']['hashtags'] for hashtag in t]\n",
    "trump_most_common_hashtags = Counter(trump_all_hashtags).most_common(15)\n",
    "\n",
    "trump_all_mentions = [hashtag for t in tweet_df[tweet_df.handle == 'realDonaldTrump']['user_mentions'] for hashtag in t]\n",
    "trump_most_common_mentions = Counter(trump_all_mentions).most_common(15)\n",
    "\n",
    "#put them on a plot\n",
    "labels, freq = zip(*trump_most_common_hashtags)\n",
    "data = {'data': freq, 'x': labels}\n",
    "bar = Bar(data, values='data',\\\n",
    "          label=cat(columns='x', sort=False),\\\n",
    "          title=\"Top Hashtags Used By Trump\", \\\n",
    "          legend = False,\n",
    "          xlabel=\"Hashtags\", ylabel=\"Number of Occurance\")\n",
    "\n",
    "labels_2, freq_2 = zip(*trump_most_common_mentions)\n",
    "data_2 = {'data_2': freq_2, 'x_2': labels_2}\n",
    "bar_2 = Bar(data_2, values='data_2',\\\n",
    "          label=cat(columns='x_2', sort=False),\\\n",
    "          title=\"Top User Mentions By Trump\", \\\n",
    "          legend = False,\n",
    "          xlabel=\"User Mentions\", ylabel=\"Number of Occurance\")\n",
    "\n",
    "output_file(\"trump_top_mentions.png.html\")\n",
    "show(row(bar,bar_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Geotracking Trump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "\n",
    "# Coordinates\n",
    "coord_frame = pd.DataFrame(tweet_df[tweet_df.handle == 'realDonaldTrump']['place'])\n",
    "coord_frame[['Long', 'Lat']] = coord_frame['place'].apply(pd.Series)    \n",
    "\n",
    "lon_min, lon_max = -130,-55\n",
    "lat_min, lat_max = 20,50\n",
    " \n",
    "plt.figure(2, figsize=(12,6))\n",
    " \n",
    "m = Basemap(projection='merc',\n",
    "             llcrnrlat=lat_min,\n",
    "             urcrnrlat=lat_max,\n",
    "             llcrnrlon=lon_min,\n",
    "             urcrnrlon=lon_max,\n",
    "             lat_ts=35,\n",
    "             resolution='i')\n",
    " \n",
    "m.fillcontinents(color='#bfbfbf')\n",
    "m.drawcountries(linewidth=0.2)\n",
    "m.drawstates(linewidth=0.2)  \n",
    "# Plot the data\n",
    "mxy = m(coord_frame['Long'].tolist(), coord_frame['Lat'].tolist())\n",
    "m.scatter(mxy[0], mxy[1], c='#ff3333', lw=0, alpha=0.5, zorder=10)\n",
    "\n",
    "plt.title('Where is Trump Tweeting From?')\n",
    "plt.savefig(\"trump.png\", dpi=300)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
