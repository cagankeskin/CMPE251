{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anaconda supplies several excellent modules\n",
    " - BeautifulSoup,\n",
    " - csv,\n",
    " - json, \n",
    " - and nltk\n",
    " \n",
    " \n",
    "### HTML\n",
    "\n",
    " - Tag Attributes Purpose\n",
    " - HTML Whole HTML document\n",
    " - HEAD Document header\n",
    " - TITLE Document title\n",
    " - BODY background, bgcolor Document body\n",
    " - H1, H2, H3, etc. Section headers\n",
    " - I, EM Emphasis\n",
    " - B, STRONG Strong emphasis\n",
    " - PRE Preformatted text\n",
    " - P, SPAN, DIV Paragraph, span, division\n",
    " - BR Line break\n",
    " - A href Hyperlink\n",
    " - IMG src, width, height Image\n",
    " - TABLE width, border Table\n",
    " - TR Table row\n",
    " - TH, TD Table header/data cell\n",
    " - OL, UL Numbered/itemized list\n",
    " - LI List item\n",
    " - DL Description list\n",
    " - DT, DD Description topic, definition\n",
    " - INPUT name User input field\n",
    " - SELECT name Pull-down menu\n",
    " \n",
    "### XML\n",
    "Any alphanumeric string can be a tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'«headers»«body»'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "# Construct soup from a string\n",
    "soup1 = BeautifulSoup(\"<HTML><HEAD>«headers»</HEAD>«body»</HTML>\", \"lxml\")\n",
    "soup1.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct soup from a local file\n",
    "    # soup2 = BeautifulSoup(open(\"myDoc.html\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file /anaconda3/lib/python3.6/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nDr. Uzay Çetin\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nDr. Uzay Çetin\\n\\nTwitter\\nFacebook\\n\\n\\n\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tMerhabalar,\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\thoş geldiniz.\\n\\n\\n\\n\\n\\n\\nKarmaşıklık ve Veri Bilimi \\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tKarmaşık Sistemler ve Veri Bilimi,\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\talanına ilgi duyuyor ve daha fazlasını öğrenmek istiyorsanız tıklayın.\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\n\\n\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tKa|Ve\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t26 Mayıs 2018 Cumartesi günü \\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tKarmaşık Sistemler ve Veri Bilimi çalıştayı,\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tİstanbul Bilgi Üniversitesi, \\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tSantral Kampüsünde E1-301 nolu amfide\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tgerçekleşecektir. Bilgi ve kayıt için tıklayın.\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\n\\n\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tProgram\\n\\n\\n\\n\\n\\n\\nSuam habet fortuna rationem (Rastlantının da, kendine has bir mantığı vardır) - Petronius, Gaius \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Construct soup from a web document\n",
    "# Remember that urlopen() does not add \"http://\"!\n",
    "soup3 = BeautifulSoup(urlopen(\"https://uzay00.github.io\"))\n",
    "text = soup3.get_text()\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dr Uzay Çetin Dr Uzay Çetin Twitter Facebook Merhabalar hoş geldiniz Karmaşıklık ve Veri Bilimi Karmaşık Sistemler ve Veri Bilimi alanına ilgi duyuyor ve daha fazlasını öğrenmek istiyorsanız tıklayın Ka Ve 26 Mayıs 2018 Cumartesi günü Karmaşık Sistemler ve Veri Bilimi çalıştayı İstanbul Bilgi Üniversitesi Santral Kampüsünde E1 301 nolu amfide gerçekleşecektir Bilgi ve kayıt için tıklayın Program Suam habet fortuna rationem Rastlantının da kendine has bir mantığı vardır Petronius Gaius'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "words = re.findall(r\"\\w+\", text)\n",
    "\" \".join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Networks of Music Groups as Success Predictors',\n",
       "  'http://www.slideshare.net/DmitryZinoviev/networks-of-music-groups-as-success-predictors'),\n",
       " ('Network Science Workshop',\n",
       "  'http://www.slideshare.net/DmitryZinoviev/workshop-20212296'),\n",
       " ('Resilience in Transaction-Oriented Networks',\n",
       "  'http://www.slideshare.net/DmitryZinoviev/resilience-in-transactional-networks'),\n",
       " ('Peer Ratings in Massive Online Social Networks',\n",
       "  'http://www.slideshare.net/DmitryZinoviev/peer-ratings-in-massive-online-social-networks')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with urlopen(\"http://www.networksciencelab.com/\") as doc:\n",
    "    soup = BeautifulSoup(doc, \"lxml\")\n",
    "links = [(link.string, link[\"href\"]) for link in soup.find_all(\"a\") if link.has_attr(\"href\")]\n",
    "links[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CSV\n",
    "\n",
    "> For potentially large files, don’t  read all records at once but use incremental, iterative, row-by-row processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with open(\"somefile.csv\", newline='') as infile:\n",
    "        reader = csv.reader(infile, delimiter=',', quotechar='\"')\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### JSON\n",
    "\n",
    "JSON is language-independent data interchange format.\n",
    "\n",
    "![](json.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "obje = [\"uzay\", \"Ali\", \"Ayse\"]\n",
    "\n",
    "# Save an object to a file\n",
    "with open(\"data.json\", \"w\") as out_json:\n",
    "    json.dump(obje, out_json, indent=None, sort_keys=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['uzay', 'Ali', 'Ayse']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load an object from a file\n",
    "with open(\"data.json\") as in_json:\n",
    "    object1 = json.load(in_json)\n",
    "    \n",
    "object1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing Texts in Natural Languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['}', 'Help', '!', ':)))', ':[', '.....', ':', 'D', '{']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import WordPunctTokenizer\n",
    "word_punct = WordPunctTokenizer()\n",
    "text = \"}Help! :))) :[ ..... :D{\"\n",
    "word_punct.tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cat'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "lemmatizer = nltk.WordNetLemmatizer()\n",
    "lemmatizer.lemmatize(\"cats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('beautiful', 'JJ'), ('world', 'NN')]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag([\"beautiful\", \"world\"])\n",
    "# An adjective and a noun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('docu', 14), ('funct', 14), ('pag', 12), ('shid', 9), ('display', 8), ('styl', 8), ('getelementbyid', 8), ('math', 6), ('ga', 6), ('applet', 6), ('introduc', 6), ('vect', 6), ('jquery', 6), ('el', 6), ('insight', 5), ('0', 5), ('top', 5), ('illust', 5), ('bas', 5), ('rect', 5), ('var', 4), ('highlight', 4), ('graph', 4), ('field', 4), ('conceiv', 4), ('linear', 4), ('non', 4), ('window', 4), ('tru', 3), ('com', 3), ('welcom', 3), ('vary', 3), ('interact', 3), ('two', 3), ('plot', 3), ('us', 3), ('solv', 3), ('dimend', 3), ('system', 3), ('mathem', 3), ('unav', 3), ('return', 3), ('js', 2), ('push', 2), ('script', 2), ('https', 2), ('http', 2), ('skip', 2), ('navig', 2), ('press', 2), ('ent', 2), ('threads', 2), ('index', 2), ('rec', 2), ('paramet', 2), ('curv', 2), ('map', 2), ('ide', 2), ('curl', 2), ('diff', 2), ('intuit', 2), ('green', 2), ('differenty', 2), ('discuss', 2), ('plan', 2), ('lin', 2), ('on', 2), ('rad', 2), ('jan', 2), ('loop', 2), ('transform', 2), ('revers', 2), ('ory', 2), ('undamp', 2), ('pendul', 2), ('dynam', 2), ('stat', 2), ('design', 2), ('read', 2), ('org', 2), ('particul', 2), ('help', 2), ('ready', 2), ('click', 2), ('slidetoggl', 2), ('obs', 2), ('inlin', 2), ('vis', 2), ('documentel', 1), ('classnam', 1), ('ua', 1), ('28169224', 1), ('1', 1), ('createel', 1), ('typ', 1), ('text', 1), ('javascrib', 1), ('asynt', 1), ('src', 1), ('loc', 1), ('protocol', 1), ('ssl', 1), ('www', 1), ('googl', 1), ('analys', 1), ('getelementsbytagnam', 1), ('parentnod', 1), ('insertbef', 1), ('main', 1), ('cont', 1), ('hom', 1), ('log', 1), ('curves', 1), ('valu', 1), ('singl', 1), ('view', 1), ('way', 1), ('interv', 1), ('onto', 1), ('fieldintuit', 1), ('subtl', 1), ('divergencecounterexampl', 1), ('diverg', 1), ('may', 1), ('appear', 1), ('expand', 1), ('behind', 1), ('theoremintroduc', 1), ('theorem', 1), ('microscop', 1), ('macroscop', 1), ('circ', 1), ('high', 1), ('dimensions', 1), ('multipl', 1), ('cent', 1), ('around', 1), ('ex', 1), ('tang', 1), ('rbas', 1), ('command', 1), ('sery', 1), ('16', 1), ('2017for', 1), ('rhow', 1), ('12', 1), ('2017visualizing', 1), ('ordin', 1), ('equations', 1), ('traject', 1), ('2d', 1), ('od', 1), ('expl', 1), ('behavy', 1), ('phas', 1), ('vers', 1), ('tim', 1), ('ad', 1), ('sept', 1), ('20', 1), ('2016', 1), ('new', 1), ('item', 1), ('three', 1), ('unit', 1), ('cub', 1), ('parallelepip', 1), ('spac', 1), ('continu', 1), ('web', 1), ('sit', 1), ('collect', 1), ('shed', 1), ('light', 1), ('und', 1), ('foc', 1), ('qualit', 1), ('describ', 1), ('rath', 1), ('get', 1), ('techn', 1), ('detail', 1), ('prec', 1), ('many', 1), ('ev', 1), ('stud', 1), ('attend', 1), ('lect', 1), ('intend', 1), ('somewh', 1), ('idea', 1), ('brows', 1), ('sequ', 1), ('subset', 1), ('find', 1), ('term', 1), ('also', 1), ('search', 1), ('im', 1), ('capt', 1), ('allow', 1), ('chang', 1), ('not', 1), ('rend', 1), ('hop', 1), ('understand', 1), ('key', 1), ('improv', 1), ('layout', 1), ('yaml', 1), ('pow', 1), ('django', 1), ('mathjax', 1), ('toggl', 1), ('nav', 1), ('menu', 1), ('icon', 1), ('pagenav', 1), ('sticky', 1), ('topspac', 1), ('unstick', 1), ('posit', 1), ('showhid', 1), ('block', 1), ('els', 1), ('inifram', 1), ('try', 1), ('self', 1), ('par', 1), ('catch', 1), ('e', 1), ('iselementinviewport', 1), ('stackoverflow', 1), ('quest', 1), ('123999', 1), ('tel', 1), ('dom', 1), ('cur', 1), ('viewport', 1), ('mod', 1), ('part', 1), ('spec', 1), ('bon', 1), ('typeof', 1), ('instanceof', 1), ('getboundingclientrect', 1), ('bottom', 1), ('right', 1), ('height', 1), ('left', 1), ('wid', 1)]\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import LancasterStemmer\n",
    "import re\n",
    "\n",
    "\n",
    "# Create a new stemmer\n",
    "ls = nltk.LancasterStemmer()\n",
    "\n",
    "# Read the file and cook a soup\n",
    "with urlopen(\"https://mathinsight.org/\") as infile:\n",
    "    soup = BeautifulSoup(infile, \"lxml\")\n",
    "\n",
    "words = re.findall(r\"\\w+\", soup.text)\n",
    "text = \" \".join(words)\n",
    "text\n",
    "\n",
    "# Extract and tokenize the text\n",
    "words = nltk.word_tokenize(text)\n",
    "\n",
    "# Convert to lowercase\n",
    "words = [w.lower() for w in words]\n",
    "\n",
    "# Eliminate stop words and stem the rest of the words\n",
    "words = [ls.stem(w) for w in words if w not in stopwords.words(\"english\") and w.isalnum()]\n",
    "\n",
    "# Tally the words\n",
    "freqs = Counter(words)\n",
    "\n",
    "print(freqs.most_common())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
